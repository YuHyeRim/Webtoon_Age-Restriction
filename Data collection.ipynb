{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32efe28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b42df10",
   "metadata": {},
   "source": [
    "# Webtoon data crawling\n",
    "\n",
    "- collect : title, author, day, genre, story(text description), platform, age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6352e5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. HTML source of webtoon page\n",
    "\n",
    "\n",
    "URL = 'https://comic.naver.com/webtoon/weekday'\n",
    "html = requests.get(URL).text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "## 2. Collect the title and list generation\n",
    "\n",
    "title = soup.find_all('a', {'class' : 'title'}) \n",
    "id_list = [] ; title_list = [] ; author_list = [] ; day_list = [] \n",
    "genre_list = [] ; story_list = [] ; platform_list = []; age_list = []\n",
    "num = 0\n",
    "\n",
    "## 3. Open the page using webdriver\n",
    "\n",
    "driver = webdriver.Chrome('location of the chrome driver') \n",
    "driver.get(URL)\n",
    "\n",
    "## 4. Crawling\n",
    "\n",
    "\n",
    "for i in range(len(title)):\n",
    "    sleep(0.5) \n",
    "    \n",
    "    page = driver.find_elements_by_class_name('title')\n",
    "    page[i].click()\n",
    "    sleep(0.5)\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser') \n",
    "\n",
    "    day = soup.find_all('ul', {'class' : 'category_tab'})\n",
    "    day = day[0].find('li', {'class' : 'on'}).text[0:1] \n",
    "\n",
    "    t = title[i].text\n",
    "    if (t in title_list):  \n",
    "        day_list[title_list.index(t)] += ', ' + day\n",
    "        driver.back()\n",
    "        continue\n",
    "        \n",
    "    id_list.append(i) ; num += 1  \n",
    "    title_list.append(t)  \n",
    "    day_list.append(day) \n",
    "    platform_list.append('Naver webtoon') \n",
    "\n",
    "    author = soup.find_all('h2') \n",
    "    author = author[1].find('span', {'class' : 'wrt_nm'}).text[8:] \n",
    "    author_list.append(author) \n",
    "\n",
    "    genre = soup.find('span', {'class' : 'genre'}).text \n",
    "    genre_list.append(genre) \n",
    "\n",
    "    story = soup.find_all('p') \n",
    "    story = str(story[3])\n",
    "    story = story.replace('<p>', '').replace('</p>', '').replace('<br/>', '\\n') \n",
    "    story_list.append(story) \n",
    "    \n",
    "    age = soup.find('span',{'class':'age'})\n",
    "    age_list.append(age)\n",
    "    \n",
    "\n",
    "    driver.back() \n",
    "    \n",
    "\n",
    "## 5. Dataframe Generation\n",
    "\n",
    "cols = []\n",
    "webtoon = pd.DataFrame(columns = cols)\n",
    "webtoon['id'] = id_list\n",
    "webtoon['title'] = title_list\n",
    "webtoon['author'] = author_list\n",
    "webtoon['day'] = day_list\n",
    "webtoon['genre'] = genre_list\n",
    "webtoon['story'] = story_list\n",
    "#webtoon['platform'] = platform_list\n",
    "webtoon['age'] = age_list\n",
    "webtoon['age'] = webtoon['age'].astype(str)\n",
    "\n",
    "for i in range(len(webtoon)):\n",
    "    webtoon.loc[i,'age'] = (webtoon.loc[i,'age']).replace('<span class=\"age\">', '').replace('</span>', '')\n",
    "\n",
    "webtoon.to_csv('naver_webtoon.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e28bf1",
   "metadata": {},
   "source": [
    "## Finished webtoon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa866b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. HTML source of webtoon page\n",
    "\n",
    "URL = 'https://comic.naver.com/webtoon/finish?view=list&order=User'\n",
    "html = requests.get(URL).text \n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "## 2. List generation\n",
    "\n",
    "#title = soup.find_all('a') \n",
    "id_list = [] ; title_list = [] ; author_list = [] ; day_list = [] \n",
    "genre_list = [] ; story_list = [] ; platform_list = []; age_list = []\n",
    "num = 0\n",
    "\n",
    "## 3. Open the page using webdriver\n",
    "\n",
    "driver = webdriver.Chrome('location of the chrome driver') \n",
    "driver.get(URL)\n",
    "\n",
    "## 4. Crawling \n",
    "\n",
    "for i in range(1,1159):\n",
    "    sleep(0.5) \n",
    "    \n",
    "    webtoon = '//*[@id=\"content\"]/div[2]/table/tbody/tr[{}]/td[1]/a/strong'.format(i)\n",
    "    button = driver.find_element_by_xpath(webtoon)\n",
    "    button.click()\n",
    "    sleep(0.8)\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser') \n",
    "\n",
    "    id_list.append(i)\n",
    "    \n",
    "    title = soup.find('span','title')\n",
    "    title_list.append(title.get_text())  \n",
    "\n",
    "    platform_list.append('네이버 웹툰') \n",
    "\n",
    "    author = soup.find_all('h2') \n",
    "    author = author[1].find('span', {'class' : 'wrt_nm'}).text[8:] \n",
    "    author_list.append(author) \n",
    "    \n",
    "    sleep(0.2)\n",
    "\n",
    "    genre = soup.find('span', {'class' : 'genre'}).text \n",
    "    genre_list.append(genre) \n",
    "\n",
    "    story = soup.find_all('p') \n",
    "    story = str(story[3])\n",
    "    story = story.replace('<p>', '').replace('</p>', '').replace('<br/>', '\\n') \n",
    "    story_list.append(story) \n",
    "    \n",
    "    age = soup.find('span',{'class':'age'})\n",
    "    \n",
    "    if age == None:\n",
    "        age_list.append(' ')\n",
    "    else:    \n",
    "        age_list.append(age.get_text())\n",
    "    \n",
    "\n",
    "    driver.back() \n",
    "    \n",
    "\n",
    "## 5. DataFrame Generation\n",
    "\n",
    "cols = []\n",
    "webtoon2 = pd.DataFrame(columns = cols)\n",
    "webtoon2['id'] = id_list_final\n",
    "webtoon2['title'] = title_list_final\n",
    "webtoon2['author'] = author_list_final\n",
    "#webtoon2['day'] = day_list_final\n",
    "webtoon2['genre'] = genre_list_final\n",
    "webtoon2['story'] = story_list_final\n",
    "webtoon2['platform'] = platform_list_final\n",
    "webtoon2['age'] = age_list_final\n",
    "\n",
    "webtoon2.to_csv('naver_webtoon2.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e620e2",
   "metadata": {},
   "source": [
    "# Data concatenate\n",
    "\n",
    "- we concatnate the webtoon1 and webtoon2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b052ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Data concatenation\n",
    "\n",
    "web_df = pd.concat([naver_1,naver_2])\n",
    "web_df.info()\n",
    "\n",
    "## 2. Drop the unused column and null\n",
    "\n",
    "# day \n",
    "web_df.drop('day', axis = 1,inplace = True)\n",
    "\n",
    " \n",
    "web_df.replace(' ', np.nan, inplace = True)\n",
    "web_df.dropna(axis = 0,inplace = True)\n",
    "\n",
    "# age label preprocessing\n",
    "web_df['age'] = web_df['age'].str.replace(\"전체 이용가\",\"전체연령가\")\n",
    "\n",
    "web_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "\n",
    "# 'age_all' column\n",
    "web_df = pd.get_dummies(data = web_df,columns = ['age'])\n",
    "web_df.rename(columns={'age_전체연령가' : 'age_all'},inplace = True)\n",
    "web_df['age_all'] = web_df['age_all'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30692e35",
   "metadata": {},
   "source": [
    "# Thumbnail collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ddcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Obtain title list\n",
    "\n",
    "title_list = naver['title'].to_list()\n",
    "\n",
    "## 2. HTML source of webtoon page\n",
    "\n",
    "URL = 'https://comic.naver.com/index'\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(URL)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "## 3. Crawling\n",
    "\n",
    "for title in title_list:\n",
    "    \n",
    "    search_box = driver.find_element_by_id('gnb.keyword')\n",
    "    search_box.clear()\n",
    "\n",
    "    search_box.send_keys(title)\n",
    "    \n",
    "    search_click = driver.find_element_by_id('search_bar_button')\n",
    "    search_click.click()\n",
    "\n",
    "    sleep(2)\n",
    "\n",
    "    webtoon = driver.find_element(By.XPATH,'//*[@id=\"content\"]/div[2]/ul/li/h5/a')\n",
    "    webtoon.click()\n",
    "\n",
    "    sleep(2)\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "    img = soup.find('div',{'class' : 'comicinfo'}).find('img')\n",
    "    \n",
    "    if '/' in title :\n",
    "        title = title.replace('/','_')\n",
    "        \n",
    "    savename = 'file save location' + title + '.jpg'\n",
    "    img_src = img['src']\n",
    "    urlretrieve(img_src, savename)\n",
    "    \n",
    "    driver.back()\n",
    "    driver.back()\n",
    "    sleep(1)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyerim_py36",
   "language": "python",
   "name": "hyerim_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
